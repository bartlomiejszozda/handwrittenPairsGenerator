{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "\n",
    "imgSizeA = 28\n",
    "imgSizeB = 28\n",
    "\n",
    "numTestSamples = 100\n",
    "numResultImagesPacks = 100\n",
    "numResultImagesInPack = 100\n",
    "batchSize = 64\n",
    "numOfLabels = 98\n",
    "\n",
    "numEpochs = 1700\n",
    "\n",
    "continueWorking = True \n",
    "# continueWorking = False\n",
    "dataDir = 'data6000_BigNetwork_labels_gen_droput0_disc1layer_dropout0_adamBeta1_05_batchSize64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "%matplotlib inline\n",
    "from helper import Helper\n",
    "import torch\n",
    "import torch.autograd.variable as Variable\n",
    "from glob import glob\n",
    "import os\n",
    "from torchvision import transforms, datasets\n",
    "from IPython import display\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#continuation\n",
    "\n",
    "#find newest model\n",
    "if continueWorking:\n",
    "    list_of_files = glob('./{}/savedModels/*'.format(dataDir)) # * means all if need specific format then *.csv\n",
    "    latest_file = max(list_of_files, key=os.path.getctime).split(\"/\")[-1]\n",
    "\n",
    "    print(int(latest_file.split('_')[2]))\n",
    "    epoch = int(latest_file.split('_')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#helpers\n",
    "\n",
    "def generatorOutputToImages(vectors):\n",
    "    return vectors.view(vectors.size(0), 1, imgSizeB, imgSizeA)\n",
    "\n",
    "def imagesToDiscriminatorInput(images):\n",
    "    return images.view(images.size(0), imgSizeA * imgSizeB)\n",
    "\n",
    "def noise(numSamples):\n",
    "    n = Variable(torch.randn(numSamples, 100))\n",
    "    if torch.cuda.is_available(): return n.cuda() \n",
    "    return n\n",
    "\n",
    "def ones(size):\n",
    "    if torch.cuda.is_available(): return Variable(torch.ones(size, 1)).cuda()\n",
    "    return Variable(torch.ones(size, 1))\n",
    "\n",
    "def zeros(size):\n",
    "    if torch.cuda.is_available(): return Variable(torch.zeros(size, 1)).cuda()\n",
    "    return Variable(torch.zeros(size, 1))\n",
    "\n",
    "def getLabelsForGenerator(size):\n",
    "    return Variable(torch.LongTensor(np.random.randint(0, numOfLabels, size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unpack data files. Needed when you run this program for the first time.\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "def concatenateSplittedArch(pathToRawDir):\n",
    "    with open(os.path.join(pathToRawDir, 'rawData.joined.tar.gz'),'wb') as wfd:\n",
    "        for f in [os.path.join(pathToRawDir, 'rawData.tar.gz.partsaa'),os.path.join(pathToRawDir, 'rawData.tar.gz.partsab'),os.path.join(pathToRawDir, 'rawData.tar.gz.partsac')]:\n",
    "            with open(f,'rb') as fd:\n",
    "                shutil.copyfileobj(fd, wfd)\n",
    "                \n",
    "def unpackArch(pathToRawDir):\n",
    "    tarFile = tarfile.open(os.path.join(pathToRawDir, 'rawData.joined.tar.gz'), \"r:gz\")\n",
    "    tarFile.extractall(pathToRawDir)\n",
    "    tarFile.close()\n",
    "    \n",
    "pathToRawDir = './generatedMNIST/MNIST/dataset/raw'\n",
    "if not(\"t10k-images-idx3-ubyte\" in os.listdir(pathToRawDir) and \"t10k-labels-idx1-ubyte\" in os.listdir(pathToRawDir) and \"train-images-idx3-ubyte\" in os.listdir(pathToRawDir) and \"train-labels-idx1-ubyte\" in os.listdir(pathToRawDir)):\n",
    "    print(\"one or more MNIST imitating data file not found. Normal if run for the first time. Unpacking arch with data...\")\n",
    "    concatenateSplittedArch(pathToRawDir)\n",
    "    unpackArch(pathToRawDir)\n",
    "    print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Dataset\n",
    "\n",
    "# from optparse import OptionParser\n",
    "# parser = OptionParser()\n",
    "# parser.add_option(\"-f\", \"--mnistDataDir\", dest=\"mnistDataDir\", default=\"./generatedMNIST\",\n",
    "#                   help=\"path to mnist data without dataset/raw\")\n",
    "\n",
    "# (options, args) = parser.parse_args()\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "mnistData = datasets.MNIST(root='./generatedMNIST', train=True, transform=transform, download=False, process=True)\n",
    "\n",
    "dataLoader = torch.utils.data.DataLoader(mnistData, batch_size=batchSize, shuffle=True)\n",
    "numBatchesPerEpoch = len(dataLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Neural Networks\n",
    "\n",
    "class DiscriminatorNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNN, self).__init__()\n",
    "        \n",
    "        self.label_emb = torch.nn.Embedding(numOfLabels,numOfLabels)\n",
    "        \n",
    "        self.inSize = imgSizeA * imgSizeB + numOfLabels\n",
    "        self.hidden0Size = 1024\n",
    "        self.hidden1Size = 512\n",
    "        self.hidden2Size = 256\n",
    "        self.outSize = 1\n",
    "        \n",
    "        def hiddenLayerSequential(numIn, numOut):\n",
    "            return torch.nn.Sequential (\n",
    "            torch.nn.Linear(numIn, numOut),\n",
    "            torch.nn.LeakyReLU(0.3),#TODO SZOZDA more leakyReLu?\n",
    "            torch.nn.Dropout(0.2)#TODO SZOZDA dropout not in first layer maybe?\n",
    "            )\n",
    "        def hiddenLayerSequentialWithoutDropout(numIn, numOut):\n",
    "            return torch.nn.Sequential (\n",
    "            torch.nn.Linear(numIn, numOut),\n",
    "            torch.nn.LeakyReLU(0.3),#TODO SZOZDA more leakyReLu?\n",
    "            )\n",
    "            \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            hiddenLayerSequentialWithoutDropout(self.inSize, self.hidden0Size),\n",
    "            hiddenLayerSequential(self.hidden0Size, self.hidden1Size),\n",
    "            hiddenLayerSequential(self.hidden1Size, self.hidden2Size),\n",
    "            torch.nn.Sequential(torch.nn.Linear(self.hidden2Size, self.outSize), torch.nn.Sigmoid())\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.layers(x)\n",
    "        return out.squeeze()\n",
    "\n",
    "    \n",
    "dNetwork = DiscriminatorNN()\n",
    "if torch.cuda.is_available():\n",
    "    dNetwork.cuda()\n",
    "\n",
    "class GeneratorNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorNN, self).__init__()\n",
    "        self.label_emb = torch.nn.Embedding(numOfLabels,numOfLabels)\n",
    "        \n",
    "        self.inSize = 100 + numOfLabels\n",
    "        self.hidden0Size = 256\n",
    "        self.hidden1Size = 512\n",
    "        self.hidden2Size = 1024\n",
    "        self.outSize = imgSizeA * imgSizeB\n",
    "        \n",
    "        def hiddenLayerSequential(numIn, numOut):\n",
    "            return torch.nn.Sequential(            \n",
    "            torch.nn.Linear(numIn, numOut),\n",
    "            torch.nn.LeakyReLU(0.3),\n",
    "            # torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.layers= torch.nn.Sequential(\n",
    "            hiddenLayerSequential(self.inSize, self.hidden0Size),\n",
    "            hiddenLayerSequential(self.hidden0Size, self.hidden1Size),\n",
    "            hiddenLayerSequential(self.hidden1Size, self.hidden2Size),\n",
    "            torch.nn.Sequential(torch.nn.Linear(self.hidden2Size, self.outSize), torch.nn.Tanh())\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "gNetwork = GeneratorNN()\n",
    "if torch.cuda.is_available():\n",
    "    gNetwork.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#training methods\n",
    "\n",
    "bceLoss = torch.nn.BCELoss()\n",
    "\n",
    "discrOptimizer = torch.optim.Adam(dNetwork.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "genOptimizer = torch.optim.Adam(gNetwork.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "def calcLossAndBackward(samples, target, labelsFromBatch):\n",
    "    prediction = dNetwork(samples, labelsFromBatch)\n",
    "    error = bceLoss(prediction, target)\n",
    "    error.backward()\n",
    "    return prediction, error\n",
    "\n",
    "def discriminatorTrain(optimizer, realSamples, generatedSamples, labelsFromBatch, labelsForGenerator):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictionReal, errorReal = calcLossAndBackward(realSamples, ones(realSamples.size(0)), labelsFromBatch)\n",
    "    predictionGen, errorGen= calcLossAndBackward(generatedSamples, zeros(generatedSamples.size(0)), labelsForGenerator)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return errorReal + errorGen, predictionReal, predictionGen\n",
    "\n",
    "def generatorTrain(optimizer, generatedSamples, labelsForGenerator):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    predictionGen, errorGen = calcLossAndBackward(generatedSamples, ones(generatedSamples.size(0)), labelsForGenerator)\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    return errorGen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train process\n",
    "\n",
    "helper = Helper(dataDir=dataDir, continueWorking=continueWorking)\n",
    "if continueWorking:\n",
    "    loadedEpoch, constNoise, constLabels = helper.loadModel(gNetwork, dNetwork, genOptimizer, discrOptimizer, epoch)\n",
    "else:\n",
    "    loadedEpoch = 0\n",
    "    constNoise = noise(numTestSamples)\n",
    "    constLabels = getLabelsForGenerator(numTestSamples).long()\n",
    "\n",
    "loadedEpoch_plus7 = loadedEpoch+7\n",
    "# loadedEpoch_plus1 = loadedEpoch+1\n",
    "\n",
    "\n",
    "def processDiscriminator(dataBatch, labelsFromBatch, labelsForGenerator):\n",
    "    realSamples = Variable(imagesToDiscriminatorInput(dataBatch))\n",
    "    if torch.cuda.is_available(): \n",
    "        realSamples = realSamples.cuda()\n",
    "    generatedSamples = gNetwork(noise(realSamples.size(0)), labelsForGenerator).detach()\n",
    "    # train\n",
    "    loss, predictionReal, predictionGen = discriminatorTrain(discrOptimizer, realSamples, generatedSamples, labelsFromBatch, labelsForGenerator)\n",
    "    return loss, predictionGen, predictionReal \n",
    "\n",
    "\n",
    "def processGenerator(dataBatch, labelsForGenerator):\n",
    "    generatedSamples = gNetwork(noise(dataBatch.size(0)), labelsForGenerator)\n",
    "    #train\n",
    "    loss = generatorTrain(genOptimizer, generatedSamples, labelsForGenerator)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def showAndLogImagesAndStats(epoch, numOfBatch, discriminatorLoss, generatorLoss, predictionGen, predictionReal):\n",
    "    #images\n",
    "    display.clear_output(True)\n",
    "    labelsForGenerator = constLabels\n",
    "    #getLabelsForGenerator(numTestSamples)\n",
    "    testingImages = generatorOutputToImages(gNetwork(constNoise, labelsForGenerator.long())).data.cpu()\n",
    "    helper.printLabels(labelsForGenerator)\n",
    "    # helper.logOnBoardAndSaveImages(dataBatch, epoch, numOfBatch, numBatchesPerEpoch);\n",
    "    helper.logOnBoardAndSaveImages(testingImages, epoch, numOfBatch, numBatchesPerEpoch);\n",
    "    \n",
    "    #stats \n",
    "    helper.showLossAndErrorsAndSaveInFile(\n",
    "                    epoch, numEpochs, numOfBatch, numBatchesPerEpoch,\n",
    "                    discriminatorLoss, generatorLoss, predictionGen, predictionReal \n",
    "                )\n",
    "\n",
    "\n",
    "for epoch in range(loadedEpoch, min(loadedEpoch_plus7, numEpochs)):\n",
    "    for numOfBatch, (dataBatch, labelsFromBatch) in enumerate(dataLoader):\n",
    "        # for label in labelsFromBatch:\n",
    "        #     if int(label) == 98:\n",
    "        #         print(label)\n",
    "        #         print('contain 98')\n",
    "        \n",
    "        # labelsForGenerator = labelsFromBatch\n",
    "        labelsForGenerator = getLabelsForGenerator(len(labelsFromBatch))\n",
    "        discriminatorLoss, predictionGen, predictionReal = processDiscriminator(dataBatch, labelsFromBatch, labelsForGenerator)\n",
    "\n",
    "        # labelsForGenerator = labelsFromBatch\n",
    "        labelsForGenerator = getLabelsForGenerator(len(labelsFromBatch))\n",
    "        generatorLoss = processGenerator(dataBatch, labelsForGenerator)\n",
    "        \n",
    "        if numOfBatch % batchSize == 0:\n",
    "            showAndLogImagesAndStats(epoch, numOfBatch, discriminatorLoss, generatorLoss, predictionGen, predictionReal)\n",
    "        # save model\n",
    "    helper.saveModel(gNetwork, dNetwork, genOptimizer, discrOptimizer, epoch+1, generatorLoss, discriminatorLoss, constNoise, constLabels) # save as epoch +1 because this is end of the epoch, and should be used as begin of the epoch+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#result images\n",
    "\n",
    "numOfBatch=0\n",
    "if epoch == numEpochs:\n",
    "    for imageNum in range(numResultImagesPacks):\n",
    "       someNoise = noise(numResultImagesInPack)\n",
    "       testingImages = generatorOutputToImages(gNetwork(someNoise, getLabelsForGenerator(numResultImagesInPack))).data.cpu()\n",
    "       helper.logOnBoardAndSaveImages(testingImages, epoch, numOfBatch, numBatchesPerEpoch, True, imageNum);\n",
    "       \"\"\"\n",
    "       helper.showLossAndErrorsAndSaveInFile(\n",
    "           epoch, numEpochs, numOfBatch, numBatchesPerEpoch,\n",
    "           discriminatorLoss, generatorLoss, predictionGen, predictionReal \n",
    "       )\n",
    "       \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%tb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
